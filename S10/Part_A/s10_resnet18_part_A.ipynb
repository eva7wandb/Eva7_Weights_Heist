{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dec25ee3-7640-4802-b2dd-b07f6203e965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning dataset download with urllib2\n",
      "Dataset downloaded\n",
      "Extracting zip file: /home/studio-lab-user/EVA7/tiny-imagenet-200.zip\n",
      "Extracted at: /home/studio-lab-user/EVA7\n",
      "Formatting: /home/studio-lab-user/EVA7/tiny-imagenet-200/val\n",
      "Cleaning up: /home/studio-lab-user/EVA7/tiny-imagenet-200/val/images\n",
      "Formatting val done\n",
      "Splitting Train+Val into 70.0-30.000000000000004\n",
      "[Old] wind: n03662601 - #: 500\n",
      "[Old] wind: n03662601 - #: 50\n",
      "[New] wnind: n03662601 - #train: 385 - #test: 165\n",
      "[Old] wind: n03544143 - #: 500\n",
      "[Old] wind: n03544143 - #: 50\n",
      "[New] wnind: n03544143 - #train: 385 - #test: 165\n",
      "[Old] wind: n01629819 - #: 500\n",
      "[Old] wind: n01629819 - #: 50\n",
      "[New] wnind: n01629819 - #train: 385 - #test: 165\n",
      "[Old] wind: n04099969 - #: 500\n",
      "[Old] wind: n04099969 - #: 50\n",
      "[New] wnind: n04099969 - #train: 385 - #test: 165\n",
      "[Old] wind: n07734744 - #: 500\n",
      "[Old] wind: n07734744 - #: 50\n",
      "[New] wnind: n07734744 - #train: 385 - #test: 165\n",
      "[Old] wind: n02231487 - #: 500\n",
      "[Old] wind: n02231487 - #: 50\n",
      "[New] wnind: n02231487 - #train: 385 - #test: 165\n",
      "[Old] wind: n03042490 - #: 500\n",
      "[Old] wind: n03042490 - #: 50\n",
      "[New] wnind: n03042490 - #train: 385 - #test: 165\n",
      "[Old] wind: n02963159 - #: 500\n",
      "[Old] wind: n02963159 - #: 50\n",
      "[New] wnind: n02963159 - #train: 385 - #test: 165\n",
      "[Old] wind: n02099712 - #: 500\n",
      "[Old] wind: n02099712 - #: 50\n",
      "[New] wnind: n02099712 - #train: 385 - #test: 165\n",
      "[Old] wind: n04074963 - #: 500\n",
      "[Old] wind: n04074963 - #: 50\n",
      "[New] wnind: n04074963 - #train: 385 - #test: 165\n",
      "[Old] wind: n07768694 - #: 500\n",
      "[Old] wind: n07768694 - #: 50\n",
      "[New] wnind: n07768694 - #train: 385 - #test: 165\n",
      "[Old] wind: n02666196 - #: 500\n",
      "[Old] wind: n02666196 - #: 50\n",
      "[New] wnind: n02666196 - #train: 385 - #test: 165\n",
      "[Old] wind: n04532106 - #: 500\n",
      "[Old] wind: n04532106 - #: 50\n",
      "[New] wnind: n04532106 - #train: 385 - #test: 165\n",
      "[Old] wind: n03804744 - #: 500\n",
      "[Old] wind: n03804744 - #: 50\n",
      "[New] wnind: n03804744 - #train: 385 - #test: 165\n",
      "[Old] wind: n02132136 - #: 500\n",
      "[Old] wind: n02132136 - #: 50\n",
      "[New] wnind: n02132136 - #train: 385 - #test: 165\n",
      "[Old] wind: n03983396 - #: 500\n",
      "[Old] wind: n03983396 - #: 50\n",
      "[New] wnind: n03983396 - #train: 385 - #test: 165\n",
      "[Old] wind: n03763968 - #: 500\n",
      "[Old] wind: n03763968 - #: 50\n",
      "[New] wnind: n03763968 - #train: 385 - #test: 165\n",
      "[Old] wind: n03796401 - #: 500\n",
      "[Old] wind: n03796401 - #: 50\n",
      "[New] wnind: n03796401 - #train: 385 - #test: 165\n",
      "[Old] wind: n03355925 - #: 500\n",
      "[Old] wind: n03355925 - #: 50\n",
      "[New] wnind: n03355925 - #train: 385 - #test: 165\n",
      "[Old] wind: n01784675 - #: 500\n",
      "[Old] wind: n01784675 - #: 50\n",
      "[New] wnind: n01784675 - #train: 385 - #test: 165\n",
      "[Old] wind: n03255030 - #: 500\n",
      "[Old] wind: n03255030 - #: 50\n",
      "[New] wnind: n03255030 - #train: 385 - #test: 165\n",
      "[Old] wind: n02793495 - #: 500\n",
      "[Old] wind: n02793495 - #: 50\n",
      "[New] wnind: n02793495 - #train: 385 - #test: 165\n",
      "[Old] wind: n02236044 - #: 500\n",
      "[Old] wind: n02236044 - #: 50\n",
      "[New] wnind: n02236044 - #train: 385 - #test: 165\n",
      "[Old] wind: n02841315 - #: 500\n",
      "[Old] wind: n02841315 - #: 50\n",
      "[New] wnind: n02841315 - #train: 385 - #test: 165\n",
      "[Old] wind: n03160309 - #: 500\n",
      "[Old] wind: n03160309 - #: 50\n",
      "[New] wnind: n03160309 - #train: 385 - #test: 165\n",
      "[Old] wind: n03814639 - #: 500\n",
      "[Old] wind: n03814639 - #: 50\n",
      "[New] wnind: n03814639 - #train: 385 - #test: 165\n",
      "[Old] wind: n02814533 - #: 500\n",
      "[Old] wind: n02814533 - #: 50\n",
      "[New] wnind: n02814533 - #train: 385 - #test: 165\n",
      "[Old] wind: n01443537 - #: 500\n",
      "[Old] wind: n01443537 - #: 50\n",
      "[New] wnind: n01443537 - #train: 385 - #test: 165\n",
      "[Old] wind: n03447447 - #: 500\n",
      "[Old] wind: n03447447 - #: 50\n",
      "[New] wnind: n03447447 - #train: 385 - #test: 165\n",
      "[Old] wind: n02364673 - #: 500\n",
      "[Old] wind: n02364673 - #: 50\n",
      "[New] wnind: n02364673 - #train: 385 - #test: 165\n",
      "[Old] wind: n02808440 - #: 500\n",
      "[Old] wind: n02808440 - #: 50\n",
      "[New] wnind: n02808440 - #train: 385 - #test: 165\n",
      "[Old] wind: n04597913 - #: 500\n",
      "[Old] wind: n04597913 - #: 50\n",
      "[New] wnind: n04597913 - #train: 385 - #test: 165\n",
      "[Old] wind: n02988304 - #: 500\n",
      "[Old] wind: n02988304 - #: 50\n",
      "[New] wnind: n02988304 - #train: 385 - #test: 165\n",
      "[Old] wind: n02948072 - #: 500\n",
      "[Old] wind: n02948072 - #: 50\n",
      "[New] wnind: n02948072 - #train: 385 - #test: 165\n",
      "[Old] wind: n04486054 - #: 500\n",
      "[Old] wind: n04486054 - #: 50\n",
      "[New] wnind: n04486054 - #train: 385 - #test: 165\n",
      "[Old] wind: n07615774 - #: 500\n",
      "[Old] wind: n07615774 - #: 50\n",
      "[New] wnind: n07615774 - #train: 385 - #test: 165\n",
      "[Old] wind: n03970156 - #: 500\n",
      "[Old] wind: n03970156 - #: 50\n",
      "[New] wnind: n03970156 - #train: 385 - #test: 165\n",
      "[Old] wind: n03388043 - #: 500\n",
      "[Old] wind: n03388043 - #: 50\n",
      "[New] wnind: n03388043 - #train: 385 - #test: 165\n",
      "[Old] wind: n04328186 - #: 500\n",
      "[Old] wind: n04328186 - #: 50\n",
      "[New] wnind: n04328186 - #train: 385 - #test: 165\n",
      "[Old] wind: n03976657 - #: 500\n",
      "[Old] wind: n03976657 - #: 50\n",
      "[New] wnind: n03976657 - #train: 385 - #test: 165\n",
      "[Old] wind: n03014705 - #: 500\n",
      "[Old] wind: n03014705 - #: 50\n",
      "[New] wnind: n03014705 - #train: 385 - #test: 165\n",
      "[Old] wind: n03201208 - #: 500\n",
      "[Old] wind: n03201208 - #: 50\n",
      "[New] wnind: n03201208 - #train: 385 - #test: 165\n",
      "[Old] wind: n02481823 - #: 500\n",
      "[Old] wind: n02481823 - #: 50\n",
      "[New] wnind: n02481823 - #train: 385 - #test: 165\n",
      "[Old] wind: n01698640 - #: 500\n",
      "[Old] wind: n01698640 - #: 50\n",
      "[New] wnind: n01698640 - #train: 385 - #test: 165\n",
      "[Old] wind: n02906734 - #: 500\n",
      "[Old] wind: n02906734 - #: 50\n",
      "[New] wnind: n02906734 - #train: 385 - #test: 165\n",
      "[Old] wind: n03733131 - #: 500\n",
      "[Old] wind: n03733131 - #: 50\n",
      "[New] wnind: n03733131 - #train: 385 - #test: 165\n",
      "[Old] wind: n02909870 - #: 500\n",
      "[Old] wind: n02909870 - #: 50\n",
      "[New] wnind: n02909870 - #train: 385 - #test: 165\n",
      "[Old] wind: n07749582 - #: 500\n",
      "[Old] wind: n07749582 - #: 50\n",
      "[New] wnind: n07749582 - #train: 385 - #test: 165\n",
      "[Old] wind: n04133789 - #: 500\n",
      "[Old] wind: n04133789 - #: 50\n",
      "[New] wnind: n04133789 - #train: 385 - #test: 165\n",
      "[Old] wind: n02892201 - #: 500\n",
      "[Old] wind: n02892201 - #: 50\n",
      "[New] wnind: n02892201 - #train: 385 - #test: 165\n",
      "[Old] wind: n07583066 - #: 500\n",
      "[Old] wind: n07583066 - #: 50\n",
      "[New] wnind: n07583066 - #train: 385 - #test: 165\n",
      "[Old] wind: n03393912 - #: 500\n",
      "[Old] wind: n03393912 - #: 50\n",
      "[New] wnind: n03393912 - #train: 385 - #test: 165\n",
      "[Old] wind: n03649909 - #: 500\n",
      "[Old] wind: n03649909 - #: 50\n",
      "[New] wnind: n03649909 - #train: 385 - #test: 165\n",
      "[Old] wind: n09246464 - #: 500\n",
      "[Old] wind: n09246464 - #: 50\n",
      "[New] wnind: n09246464 - #train: 385 - #test: 165\n",
      "[Old] wind: n03937543 - #: 500\n",
      "[Old] wind: n03937543 - #: 50\n",
      "[New] wnind: n03937543 - #train: 385 - #test: 165\n",
      "[Old] wind: n02730930 - #: 500\n",
      "[Old] wind: n02730930 - #: 50\n",
      "[New] wnind: n02730930 - #train: 385 - #test: 165\n",
      "[Old] wind: n04149813 - #: 500\n",
      "[Old] wind: n04149813 - #: 50\n",
      "[New] wnind: n04149813 - #train: 385 - #test: 165\n",
      "[Old] wind: n01917289 - #: 500\n",
      "[Old] wind: n01917289 - #: 50\n",
      "[New] wnind: n01917289 - #train: 385 - #test: 165\n",
      "[Old] wind: n02415577 - #: 500\n",
      "[Old] wind: n02415577 - #: 50\n",
      "[New] wnind: n02415577 - #train: 385 - #test: 165\n",
      "[Old] wind: n02123394 - #: 500\n",
      "[Old] wind: n02123394 - #: 50\n",
      "[New] wnind: n02123394 - #train: 385 - #test: 165\n",
      "[Old] wind: n02125311 - #: 500\n",
      "[Old] wind: n02125311 - #: 50\n",
      "[New] wnind: n02125311 - #train: 385 - #test: 165\n",
      "[Old] wind: n01983481 - #: 500\n",
      "[Old] wind: n01983481 - #: 50\n",
      "[New] wnind: n01983481 - #train: 385 - #test: 165\n",
      "[Old] wind: n02669723 - #: 500\n",
      "[Old] wind: n02669723 - #: 50\n",
      "[New] wnind: n02669723 - #train: 385 - #test: 165\n",
      "[Old] wind: n01774750 - #: 500\n",
      "[Old] wind: n01774750 - #: 50\n",
      "[New] wnind: n01774750 - #train: 385 - #test: 165\n",
      "[Old] wind: n03977966 - #: 500\n",
      "[Old] wind: n03977966 - #: 50\n",
      "[New] wnind: n03977966 - #train: 385 - #test: 165\n",
      "[Old] wind: n01770393 - #: 500\n",
      "[Old] wind: n01770393 - #: 50\n",
      "[New] wnind: n01770393 - #train: 385 - #test: 165\n",
      "[Old] wind: n04179913 - #: 500\n",
      "[Old] wind: n04179913 - #: 50\n",
      "[New] wnind: n04179913 - #train: 385 - #test: 165\n",
      "[Old] wind: n02950826 - #: 500\n",
      "[Old] wind: n02950826 - #: 50\n",
      "[New] wnind: n02950826 - #train: 385 - #test: 165\n",
      "[Old] wind: n02814860 - #: 500\n",
      "[Old] wind: n02814860 - #: 50\n",
      "[New] wnind: n02814860 - #train: 385 - #test: 165\n",
      "[Old] wind: n02395406 - #: 500\n",
      "[Old] wind: n02395406 - #: 50\n",
      "[New] wnind: n02395406 - #train: 385 - #test: 165\n",
      "[Old] wind: n04356056 - #: 500\n",
      "[Old] wind: n04356056 - #: 50\n",
      "[New] wnind: n04356056 - #train: 385 - #test: 165\n",
      "[Old] wind: n07695742 - #: 500\n",
      "[Old] wind: n07695742 - #: 50\n",
      "[New] wnind: n07695742 - #train: 385 - #test: 165\n",
      "[Old] wind: n04456115 - #: 500\n",
      "[Old] wind: n04456115 - #: 50\n",
      "[New] wnind: n04456115 - #train: 385 - #test: 165\n",
      "[Old] wind: n04285008 - #: 500\n",
      "[Old] wind: n04285008 - #: 50\n",
      "[New] wnind: n04285008 - #train: 385 - #test: 165\n",
      "[Old] wind: n04465501 - #: 500\n",
      "[Old] wind: n04465501 - #: 50\n",
      "[New] wnind: n04465501 - #train: 385 - #test: 165\n",
      "[Old] wind: n03100240 - #: 500\n",
      "[Old] wind: n03100240 - #: 50\n",
      "[New] wnind: n03100240 - #train: 385 - #test: 165\n",
      "[Old] wind: n02403003 - #: 500\n",
      "[Old] wind: n02403003 - #: 50\n",
      "[New] wnind: n02403003 - #train: 385 - #test: 165\n",
      "[Old] wind: n02226429 - #: 500\n",
      "[Old] wind: n02226429 - #: 50\n",
      "[New] wnind: n02226429 - #train: 385 - #test: 165\n",
      "[Old] wind: n03400231 - #: 500\n",
      "[Old] wind: n03400231 - #: 50\n",
      "[New] wnind: n03400231 - #train: 385 - #test: 165\n",
      "[Old] wind: n04275548 - #: 500\n",
      "[Old] wind: n04275548 - #: 50\n",
      "[New] wnind: n04275548 - #train: 385 - #test: 165\n",
      "[Old] wind: n01945685 - #: 500\n",
      "[Old] wind: n01945685 - #: 50\n",
      "[New] wnind: n01945685 - #train: 385 - #test: 165\n",
      "[Old] wind: n02106662 - #: 500\n",
      "[Old] wind: n02106662 - #: 50\n",
      "[New] wnind: n02106662 - #train: 385 - #test: 165\n",
      "[Old] wind: n02129165 - #: 500\n",
      "[Old] wind: n02129165 - #: 50\n",
      "[New] wnind: n02129165 - #train: 385 - #test: 165\n",
      "[Old] wind: n02190166 - #: 500\n",
      "[Old] wind: n02190166 - #: 50\n",
      "[New] wnind: n02190166 - #train: 385 - #test: 165\n",
      "[Old] wind: n02802426 - #: 500\n",
      "[Old] wind: n02802426 - #: 50\n",
      "[New] wnind: n02802426 - #train: 385 - #test: 165\n",
      "[Old] wind: n04067472 - #: 500\n",
      "[Old] wind: n04067472 - #: 50\n",
      "[New] wnind: n04067472 - #train: 385 - #test: 165\n",
      "[Old] wind: n09428293 - #: 500\n",
      "[Old] wind: n09428293 - #: 50\n",
      "[New] wnind: n09428293 - #train: 385 - #test: 165\n",
      "[Old] wind: n04371430 - #: 500\n",
      "[Old] wind: n04371430 - #: 50\n",
      "[New] wnind: n04371430 - #train: 385 - #test: 165\n",
      "[Old] wind: n01882714 - #: 500\n",
      "[Old] wind: n01882714 - #: 50\n",
      "[New] wnind: n01882714 - #train: 385 - #test: 165\n",
      "[Old] wind: n07747607 - #: 500\n",
      "[Old] wind: n07747607 - #: 50\n",
      "[New] wnind: n07747607 - #train: 385 - #test: 165\n",
      "[Old] wind: n04376876 - #: 500\n",
      "[Old] wind: n04376876 - #: 50\n",
      "[New] wnind: n04376876 - #train: 385 - #test: 165\n",
      "[Old] wind: n07579787 - #: 500\n",
      "[Old] wind: n07579787 - #: 50\n",
      "[New] wnind: n07579787 - #train: 385 - #test: 165\n",
      "[Old] wind: n12267677 - #: 500\n",
      "[Old] wind: n12267677 - #: 50\n",
      "[New] wnind: n12267677 - #train: 385 - #test: 165\n",
      "[Old] wind: n03670208 - #: 500\n",
      "[Old] wind: n03670208 - #: 50\n",
      "[New] wnind: n03670208 - #train: 385 - #test: 165\n",
      "[Old] wind: n02883205 - #: 500\n",
      "[Old] wind: n02883205 - #: 50\n",
      "[New] wnind: n02883205 - #train: 385 - #test: 165\n",
      "[Old] wind: n04023962 - #: 500\n",
      "[Old] wind: n04023962 - #: 50\n",
      "[New] wnind: n04023962 - #train: 385 - #test: 165\n",
      "[Old] wind: n07920052 - #: 500\n",
      "[Old] wind: n07920052 - #: 50\n",
      "[New] wnind: n07920052 - #train: 385 - #test: 165\n",
      "[Old] wind: n02279972 - #: 500\n",
      "[Old] wind: n02279972 - #: 50\n",
      "[New] wnind: n02279972 - #train: 385 - #test: 165\n",
      "[Old] wind: n02509815 - #: 500\n",
      "[Old] wind: n02509815 - #: 50\n",
      "[New] wnind: n02509815 - #train: 385 - #test: 165\n",
      "[Old] wind: n02233338 - #: 500\n",
      "[Old] wind: n02233338 - #: 50\n",
      "[New] wnind: n02233338 - #train: 385 - #test: 165\n",
      "[Old] wind: n04562935 - #: 500\n",
      "[Old] wind: n04562935 - #: 50\n",
      "[New] wnind: n04562935 - #train: 385 - #test: 165\n",
      "[Old] wind: n03599486 - #: 500\n",
      "[Old] wind: n03599486 - #: 50\n",
      "[New] wnind: n03599486 - #train: 385 - #test: 165\n",
      "[Old] wind: n04008634 - #: 500\n",
      "[Old] wind: n04008634 - #: 50\n",
      "[New] wnind: n04008634 - #train: 385 - #test: 165\n",
      "[Old] wind: n03770439 - #: 500\n",
      "[Old] wind: n03770439 - #: 50\n",
      "[New] wnind: n03770439 - #train: 385 - #test: 165\n",
      "[Old] wind: n03404251 - #: 500\n",
      "[Old] wind: n03404251 - #: 50\n",
      "[New] wnind: n03404251 - #train: 385 - #test: 165\n",
      "[Old] wind: n04399382 - #: 500\n",
      "[Old] wind: n04399382 - #: 50\n",
      "[New] wnind: n04399382 - #train: 385 - #test: 165\n",
      "[Old] wind: n03126707 - #: 500\n",
      "[Old] wind: n03126707 - #: 50\n",
      "[New] wnind: n03126707 - #train: 385 - #test: 165\n",
      "[Old] wind: n03424325 - #: 500\n",
      "[Old] wind: n03424325 - #: 50\n",
      "[New] wnind: n03424325 - #train: 385 - #test: 165\n",
      "[Old] wind: n01742172 - #: 500\n",
      "[Old] wind: n01742172 - #: 50\n",
      "[New] wnind: n01742172 - #train: 385 - #test: 165\n",
      "[Old] wind: n07614500 - #: 500\n",
      "[Old] wind: n07614500 - #: 50\n",
      "[New] wnind: n07614500 - #train: 385 - #test: 165\n",
      "[Old] wind: n02843684 - #: 500\n",
      "[Old] wind: n02843684 - #: 50\n",
      "[New] wnind: n02843684 - #train: 385 - #test: 165\n",
      "[Old] wind: n02795169 - #: 500\n",
      "[Old] wind: n02795169 - #: 50\n",
      "[New] wnind: n02795169 - #train: 385 - #test: 165\n",
      "[Old] wind: n01644900 - #: 500\n",
      "[Old] wind: n01644900 - #: 50\n",
      "[New] wnind: n01644900 - #train: 385 - #test: 165\n",
      "[Old] wind: n02056570 - #: 500\n",
      "[Old] wind: n02056570 - #: 50\n",
      "[New] wnind: n02056570 - #train: 385 - #test: 165\n",
      "[Old] wind: n03980874 - #: 500\n",
      "[Old] wind: n03980874 - #: 50\n",
      "[New] wnind: n03980874 - #train: 385 - #test: 165\n",
      "[Old] wind: n02423022 - #: 500\n",
      "[Old] wind: n02423022 - #: 50\n",
      "[New] wnind: n02423022 - #train: 385 - #test: 165\n",
      "[Old] wind: n02206856 - #: 500\n",
      "[Old] wind: n02206856 - #: 50\n",
      "[New] wnind: n02206856 - #train: 385 - #test: 165\n",
      "[Old] wind: n02823428 - #: 500\n",
      "[Old] wind: n02823428 - #: 50\n",
      "[New] wnind: n02823428 - #train: 385 - #test: 165\n",
      "[Old] wind: n02927161 - #: 500\n",
      "[Old] wind: n02927161 - #: 50\n",
      "[New] wnind: n02927161 - #train: 385 - #test: 165\n",
      "[Old] wind: n02769748 - #: 500\n",
      "[Old] wind: n02769748 - #: 50\n",
      "[New] wnind: n02769748 - #train: 385 - #test: 165\n",
      "[Old] wind: n03179701 - #: 500\n",
      "[Old] wind: n03179701 - #: 50\n",
      "[New] wnind: n03179701 - #train: 385 - #test: 165\n",
      "[Old] wind: n02504458 - #: 500\n",
      "[Old] wind: n02504458 - #: 50\n",
      "[New] wnind: n02504458 - #train: 385 - #test: 165\n",
      "[Old] wind: n02837789 - #: 500\n",
      "[Old] wind: n02837789 - #: 50\n",
      "[New] wnind: n02837789 - #train: 385 - #test: 165\n",
      "[Old] wind: n02099601 - #: 500\n",
      "[Old] wind: n02099601 - #: 50\n",
      "[New] wnind: n02099601 - #train: 385 - #test: 165\n",
      "[Old] wind: n03837869 - #: 500\n",
      "[Old] wind: n03837869 - #: 50\n",
      "[New] wnind: n03837869 - #train: 385 - #test: 165\n",
      "[Old] wind: n04265275 - #: 500\n",
      "[Old] wind: n04265275 - #: 50\n",
      "[New] wnind: n04265275 - #train: 385 - #test: 165\n",
      "[Old] wind: n02791270 - #: 500\n",
      "[Old] wind: n02791270 - #: 50\n",
      "[New] wnind: n02791270 - #train: 385 - #test: 165\n",
      "[Old] wind: n07875152 - #: 500\n",
      "[Old] wind: n07875152 - #: 50\n",
      "[New] wnind: n07875152 - #train: 385 - #test: 165\n",
      "[Old] wind: n03992509 - #: 500\n",
      "[Old] wind: n03992509 - #: 50\n",
      "[New] wnind: n03992509 - #train: 385 - #test: 165\n",
      "[Old] wind: n02002724 - #: 500\n",
      "[Old] wind: n02002724 - #: 50\n",
      "[New] wnind: n02002724 - #train: 385 - #test: 165\n",
      "[Old] wind: n04146614 - #: 500\n",
      "[Old] wind: n04146614 - #: 50\n",
      "[New] wnind: n04146614 - #train: 385 - #test: 165\n",
      "[Old] wind: n02410509 - #: 500\n",
      "[Old] wind: n02410509 - #: 50\n",
      "[New] wnind: n02410509 - #train: 385 - #test: 165\n",
      "[Old] wind: n06596364 - #: 500\n",
      "[Old] wind: n06596364 - #: 50\n",
      "[New] wnind: n06596364 - #train: 385 - #test: 165\n",
      "[Old] wind: n01641577 - #: 500\n",
      "[Old] wind: n01641577 - #: 50\n",
      "[New] wnind: n01641577 - #train: 385 - #test: 165\n",
      "[Old] wind: n04417672 - #: 500\n",
      "[Old] wind: n04417672 - #: 50\n",
      "[New] wnind: n04417672 - #train: 385 - #test: 165\n",
      "[Old] wind: n03854065 - #: 500\n",
      "[Old] wind: n03854065 - #: 50\n",
      "[New] wnind: n03854065 - #train: 385 - #test: 165\n",
      "[Old] wind: n02268443 - #: 500\n",
      "[Old] wind: n02268443 - #: 50\n",
      "[New] wnind: n02268443 - #train: 385 - #test: 165\n",
      "[Old] wind: n01774384 - #: 500\n",
      "[Old] wind: n01774384 - #: 50\n",
      "[New] wnind: n01774384 - #train: 385 - #test: 165\n",
      "[Old] wind: n03838899 - #: 500\n",
      "[Old] wind: n03838899 - #: 50\n",
      "[New] wnind: n03838899 - #train: 385 - #test: 165\n",
      "[Old] wind: n07871810 - #: 500\n",
      "[Old] wind: n07871810 - #: 50\n",
      "[New] wnind: n07871810 - #train: 385 - #test: 165\n",
      "[Old] wind: n09193705 - #: 500\n",
      "[Old] wind: n09193705 - #: 50\n",
      "[New] wnind: n09193705 - #train: 385 - #test: 165\n",
      "[Old] wind: n01855672 - #: 500\n",
      "[Old] wind: n01855672 - #: 50\n",
      "[New] wnind: n01855672 - #train: 385 - #test: 165\n",
      "[Old] wind: n04070727 - #: 500\n",
      "[Old] wind: n04070727 - #: 50\n",
      "[New] wnind: n04070727 - #train: 385 - #test: 165\n",
      "[Old] wind: n03617480 - #: 500\n",
      "[Old] wind: n03617480 - #: 50\n",
      "[New] wnind: n03617480 - #train: 385 - #test: 165\n",
      "[Old] wind: n04487081 - #: 500\n",
      "[Old] wind: n04487081 - #: 50\n",
      "[New] wnind: n04487081 - #train: 385 - #test: 165\n",
      "[Old] wind: n03706229 - #: 500\n",
      "[Old] wind: n03706229 - #: 50\n",
      "[New] wnind: n03706229 - #train: 385 - #test: 165\n",
      "[Old] wind: n02699494 - #: 500\n",
      "[Old] wind: n02699494 - #: 50\n",
      "[New] wnind: n02699494 - #train: 385 - #test: 165\n",
      "[Old] wind: n07711569 - #: 500\n",
      "[Old] wind: n07711569 - #: 50\n",
      "[New] wnind: n07711569 - #train: 385 - #test: 165\n",
      "[Old] wind: n09332890 - #: 500\n",
      "[Old] wind: n09332890 - #: 50\n",
      "[New] wnind: n09332890 - #train: 385 - #test: 165\n",
      "[Old] wind: n02058221 - #: 500\n",
      "[Old] wind: n02058221 - #: 50\n",
      "[New] wnind: n02058221 - #train: 385 - #test: 165\n",
      "[Old] wind: n02321529 - #: 500\n",
      "[Old] wind: n02321529 - #: 50\n",
      "[New] wnind: n02321529 - #train: 385 - #test: 165\n",
      "[Old] wind: n04560804 - #: 500\n",
      "[Old] wind: n04560804 - #: 50\n",
      "[New] wnind: n04560804 - #train: 385 - #test: 165\n",
      "[Old] wind: n02999410 - #: 500\n",
      "[Old] wind: n02999410 - #: 50\n",
      "[New] wnind: n02999410 - #train: 385 - #test: 165\n",
      "[Old] wind: n01910747 - #: 500\n",
      "[Old] wind: n01910747 - #: 50\n",
      "[New] wnind: n01910747 - #train: 385 - #test: 165\n",
      "[Old] wind: n04366367 - #: 500\n",
      "[Old] wind: n04366367 - #: 50\n",
      "[New] wnind: n04366367 - #train: 385 - #test: 165\n",
      "[Old] wind: n07715103 - #: 500\n",
      "[Old] wind: n07715103 - #: 50\n",
      "[New] wnind: n07715103 - #train: 385 - #test: 165\n",
      "[Old] wind: n04596742 - #: 500\n",
      "[Old] wind: n04596742 - #: 50\n",
      "[New] wnind: n04596742 - #train: 385 - #test: 165\n",
      "[Old] wind: n03584254 - #: 500\n",
      "[Old] wind: n03584254 - #: 50\n",
      "[New] wnind: n03584254 - #train: 385 - #test: 165\n",
      "[Old] wind: n04259630 - #: 500\n",
      "[Old] wind: n04259630 - #: 50\n",
      "[New] wnind: n04259630 - #train: 385 - #test: 165\n",
      "[Old] wind: n09256479 - #: 500\n",
      "[Old] wind: n09256479 - #: 50\n",
      "[New] wnind: n09256479 - #train: 385 - #test: 165\n",
      "[Old] wind: n02977058 - #: 500\n",
      "[Old] wind: n02977058 - #: 50\n",
      "[New] wnind: n02977058 - #train: 385 - #test: 165\n",
      "[Old] wind: n07720875 - #: 500\n",
      "[Old] wind: n07720875 - #: 50\n",
      "[New] wnind: n07720875 - #train: 385 - #test: 165\n",
      "[Old] wind: n04251144 - #: 500\n",
      "[Old] wind: n04251144 - #: 50\n",
      "[New] wnind: n04251144 - #train: 385 - #test: 165\n",
      "[Old] wind: n02085620 - #: 500\n",
      "[Old] wind: n02085620 - #: 50\n",
      "[New] wnind: n02085620 - #train: 385 - #test: 165\n",
      "[Old] wind: n04540053 - #: 500\n",
      "[Old] wind: n04540053 - #: 50\n",
      "[New] wnind: n04540053 - #train: 385 - #test: 165\n",
      "[Old] wind: n02917067 - #: 500\n",
      "[Old] wind: n02917067 - #: 50\n",
      "[New] wnind: n02917067 - #train: 385 - #test: 165\n",
      "[Old] wind: n04311004 - #: 500\n",
      "[Old] wind: n04311004 - #: 50\n",
      "[New] wnind: n04311004 - #train: 385 - #test: 165\n",
      "[Old] wind: n04118538 - #: 500\n",
      "[Old] wind: n04118538 - #: 50\n",
      "[New] wnind: n04118538 - #train: 385 - #test: 165\n",
      "[Old] wind: n01984695 - #: 500\n",
      "[Old] wind: n01984695 - #: 50\n",
      "[New] wnind: n01984695 - #train: 385 - #test: 165\n",
      "[Old] wind: n02124075 - #: 500\n",
      "[Old] wind: n02124075 - #: 50\n",
      "[New] wnind: n02124075 - #train: 385 - #test: 165\n",
      "[Old] wind: n04254777 - #: 500\n",
      "[Old] wind: n04254777 - #: 50\n",
      "[New] wnind: n04254777 - #train: 385 - #test: 165\n",
      "[Old] wind: n07753592 - #: 500\n",
      "[Old] wind: n07753592 - #: 50\n",
      "[New] wnind: n07753592 - #train: 385 - #test: 165\n",
      "[Old] wind: n02113799 - #: 500\n",
      "[Old] wind: n02113799 - #: 50\n",
      "[New] wnind: n02113799 - #train: 385 - #test: 165\n",
      "[Old] wind: n02074367 - #: 500\n",
      "[Old] wind: n02074367 - #: 50\n",
      "[New] wnind: n02074367 - #train: 385 - #test: 165\n",
      "[Old] wind: n01768244 - #: 500\n",
      "[Old] wind: n01768244 - #: 50\n",
      "[New] wnind: n01768244 - #train: 385 - #test: 165\n",
      "[Old] wind: n04507155 - #: 500\n",
      "[Old] wind: n04507155 - #: 50\n",
      "[New] wnind: n04507155 - #train: 385 - #test: 165\n",
      "[Old] wind: n04532670 - #: 500\n",
      "[Old] wind: n04532670 - #: 50\n",
      "[New] wnind: n04532670 - #train: 385 - #test: 165\n",
      "[Old] wind: n07873807 - #: 500\n",
      "[Old] wind: n07873807 - #: 50\n",
      "[New] wnind: n07873807 - #train: 385 - #test: 165\n",
      "[Old] wind: n02437312 - #: 500\n",
      "[Old] wind: n02437312 - #: 50\n",
      "[New] wnind: n02437312 - #train: 385 - #test: 165\n",
      "[Old] wind: n04501370 - #: 500\n",
      "[Old] wind: n04501370 - #: 50\n",
      "[New] wnind: n04501370 - #train: 385 - #test: 165\n",
      "[Old] wind: n03902125 - #: 500\n",
      "[Old] wind: n03902125 - #: 50\n",
      "[New] wnind: n03902125 - #train: 385 - #test: 165\n",
      "[Old] wind: n02815834 - #: 500\n",
      "[Old] wind: n02815834 - #: 50\n",
      "[New] wnind: n02815834 - #train: 385 - #test: 165\n",
      "[Old] wind: n01944390 - #: 500\n",
      "[Old] wind: n01944390 - #: 50\n",
      "[New] wnind: n01944390 - #train: 385 - #test: 165\n",
      "[Old] wind: n03089624 - #: 500\n",
      "[Old] wind: n03089624 - #: 50\n",
      "[New] wnind: n03089624 - #train: 385 - #test: 165\n",
      "[Old] wind: n02788148 - #: 500\n",
      "[Old] wind: n02788148 - #: 50\n",
      "[New] wnind: n02788148 - #train: 385 - #test: 165\n",
      "[Old] wind: n03250847 - #: 500\n",
      "[Old] wind: n03250847 - #: 50\n",
      "[New] wnind: n03250847 - #train: 385 - #test: 165\n",
      "[Old] wind: n03637318 - #: 500\n",
      "[Old] wind: n03637318 - #: 50\n",
      "[New] wnind: n03637318 - #train: 385 - #test: 165\n",
      "[Old] wind: n02480495 - #: 500\n",
      "[Old] wind: n02480495 - #: 50\n",
      "[New] wnind: n02480495 - #train: 385 - #test: 165\n",
      "[Old] wind: n02094433 - #: 500\n",
      "[Old] wind: n02094433 - #: 50\n",
      "[New] wnind: n02094433 - #train: 385 - #test: 165\n",
      "[Old] wind: n03085013 - #: 500\n",
      "[Old] wind: n03085013 - #: 50\n",
      "[New] wnind: n03085013 - #train: 385 - #test: 165\n",
      "[Old] wind: n01950731 - #: 500\n",
      "[Old] wind: n01950731 - #: 50\n",
      "[New] wnind: n01950731 - #train: 385 - #test: 165\n",
      "[Old] wind: n03444034 - #: 500\n",
      "[Old] wind: n03444034 - #: 50\n",
      "[New] wnind: n03444034 - #train: 385 - #test: 165\n",
      "[Old] wind: n02165456 - #: 500\n",
      "[Old] wind: n02165456 - #: 50\n",
      "[New] wnind: n02165456 - #train: 385 - #test: 165\n",
      "[Old] wind: n02281406 - #: 500\n",
      "[Old] wind: n02281406 - #: 50\n",
      "[New] wnind: n02281406 - #train: 385 - #test: 165\n",
      "[Old] wind: n03891332 - #: 500\n",
      "[Old] wind: n03891332 - #: 50\n",
      "[New] wnind: n03891332 - #train: 385 - #test: 165\n",
      "[Old] wind: n02486410 - #: 500\n",
      "[Old] wind: n02486410 - #: 50\n",
      "[New] wnind: n02486410 - #train: 385 - #test: 165\n",
      "[Old] wind: n03026506 - #: 500\n",
      "[Old] wind: n03026506 - #: 50\n",
      "[New] wnind: n03026506 - #train: 385 - #test: 165\n",
      "[Old] wind: n04398044 - #: 500\n",
      "[Old] wind: n04398044 - #: 50\n",
      "[New] wnind: n04398044 - #train: 385 - #test: 165\n",
      "[Old] wind: n02123045 - #: 500\n",
      "[Old] wind: n02123045 - #: 50\n",
      "[New] wnind: n02123045 - #train: 385 - #test: 165\n",
      "[Old] wind: n03930313 - #: 500\n",
      "[Old] wind: n03930313 - #: 50\n",
      "[New] wnind: n03930313 - #train: 385 - #test: 165\n",
      "[New] #train: 77000 - #test: 33000\n",
      "Cleaning up: /home/studio-lab-user/EVA7/tiny-imagenet-200/train\n",
      "Cleaning up: /home/studio-lab-user/EVA7/tiny-imagenet-200/val\n",
      "Created new train data at: /home/studio-lab-user/EVA7/tiny-imagenet-200/new_train\n",
      "Cleaning new test data at: /home/studio-lab-user/EVA7/tiny-imagenet-200/new_test\n",
      "Splitting dataset done\n"
     ]
    }
   ],
   "source": [
    "#!python prepare_tiny-imagenet-200.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbc75169-4af2-481f-9a72-804b955b5fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m zipfile -c tiny_image_net_200.zip tiny-imagenet-200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6622c096-5128-46c5-b828-d87d19790b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: albumentations in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from albumentations) (1.21.4)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from albumentations) (0.19.0)\n",
      "Requirement already satisfied: PyYAML in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from albumentations) (6.0)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from albumentations) (4.5.4.60)\n",
      "Requirement already satisfied: qudida>=0.0.4 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from albumentations) (0.0.4)\n",
      "Requirement already satisfied: scipy in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from albumentations) (1.7.3)\n",
      "Requirement already satisfied: typing-extensions in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from qudida>=0.0.4->albumentations) (4.0.1)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from qudida>=0.0.4->albumentations) (1.0.1)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from scikit-image>=0.16.1->albumentations) (2.13.3)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from scikit-image>=0.16.1->albumentations) (8.4.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from scikit-image>=0.16.1->albumentations) (2.6.3)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from scikit-image>=0.16.1->albumentations) (2021.11.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from scikit-image>=0.16.1->albumentations) (21.3)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from scikit-image>=0.16.1->albumentations) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from packaging>=20.0->scikit-image>=0.16.1->albumentations) (3.0.6)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.1.0)\n",
      "fatal: destination path 'torch-cam' already exists and is not an empty directory.\n",
      "Obtaining file:///home/studio-lab-user/EVA7/torch-cam\n",
      "Requirement already satisfied: torch>=1.5.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torchcam==0.3.2.dev0+9b2cc3b) (1.10.0)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torchcam==0.3.2.dev0+9b2cc3b) (1.21.4)\n",
      "Requirement already satisfied: Pillow>=8.3.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torchcam==0.3.2.dev0+9b2cc3b) (8.4.0)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torchcam==0.3.2.dev0+9b2cc3b) (3.5.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib>=3.0.0->torchcam==0.3.2.dev0+9b2cc3b) (1.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib>=3.0.0->torchcam==0.3.2.dev0+9b2cc3b) (3.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib>=3.0.0->torchcam==0.3.2.dev0+9b2cc3b) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib>=3.0.0->torchcam==0.3.2.dev0+9b2cc3b) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib>=3.0.0->torchcam==0.3.2.dev0+9b2cc3b) (4.28.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib>=3.0.0->torchcam==0.3.2.dev0+9b2cc3b) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->torchcam==0.3.2.dev0+9b2cc3b) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch>=1.5.1->torchcam==0.3.2.dev0+9b2cc3b) (4.0.1)\n",
      "Installing collected packages: torchcam\n",
      "  Attempting uninstall: torchcam\n",
      "    Found existing installation: torchcam 0.3.2.dev0+9b2cc3b\n",
      "    Uninstalling torchcam-0.3.2.dev0+9b2cc3b:\n",
      "      Successfully uninstalled torchcam-0.3.2.dev0+9b2cc3b\n",
      "  Running setup.py develop for torchcam\n",
      "Successfully installed torchcam-0.3.2.dev0+9b2cc3b\n",
      "Requirement already satisfied: torch-lr-finder in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (0.2.1)\n",
      "Requirement already satisfied: packaging in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch-lr-finder) (21.3)\n",
      "Requirement already satisfied: torch>=0.4.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch-lr-finder) (1.10.0)\n",
      "Requirement already satisfied: matplotlib in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch-lr-finder) (3.5.1)\n",
      "Requirement already satisfied: numpy in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch-lr-finder) (1.21.4)\n",
      "Requirement already satisfied: tqdm in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch-lr-finder) (4.62.3)\n",
      "Requirement already satisfied: typing-extensions in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch>=0.4.1->torch-lr-finder) (4.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib->torch-lr-finder) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib->torch-lr-finder) (4.28.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib->torch-lr-finder) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib->torch-lr-finder) (8.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib->torch-lr-finder) (3.0.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib->torch-lr-finder) (1.3.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->torch-lr-finder) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade albumentations\n",
    "!git clone https://github.com/frgfm/torch-cam.git\n",
    "!pip install -e torch-cam/.\n",
    "!pip install torch-lr-finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da2b380f-15a9-4dba-a252-c9747311f08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (1.10.0)\n",
      "Requirement already satisfied: typing-extensions in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (4.0.1)\n",
      "Requirement already satisfied: torchvision in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (0.11.1)\n",
      "Requirement already satisfied: torch==1.10.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torchvision) (1.10.0)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torchvision) (8.4.0)\n",
      "Requirement already satisfied: numpy in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torchvision) (1.21.4)\n",
      "Requirement already satisfied: typing-extensions in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch==1.10.0->torchvision) (4.0.1)\n",
      "Requirement already satisfied: torchsummary in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (1.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install torchvision\n",
    "!pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c56158b-325a-4311-98e7-c1f1c861db49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Weights_Heist_Flow'...\n",
      "remote: Enumerating objects: 230, done.\u001b[K\n",
      "remote: Counting objects: 100% (230/230), done.\u001b[K\n",
      "remote: Compressing objects: 100% (196/196), done.\u001b[K\n",
      "remote: Total 230 (delta 99), reused 109 (delta 31), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (230/230), 428.00 KiB | 3.86 MiB/s, done.\n",
      "Resolving deltas: 100% (99/99), done.\n"
     ]
    }
   ],
   "source": [
    "#!git clone https://github.com/eva7wandb/Weights_Heist_Flow.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6d249aa-da48-4c22-b2b3-a64d1f1a035e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/EVA7/Weights_Heist_Flow\n"
     ]
    }
   ],
   "source": [
    "%cd Weights_Heist_Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfbb5a47-ddec-4f7d-a040-2c19c76a5650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/EVA7/Weights_Heist_Flow\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45f09478-45f2-4e01-b4a1-9f41ab70f255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] seed set 1\n",
      "[INFO] Cuda Avaliable :  True\n",
      "[INFO] device :  cuda\n"
     ]
    }
   ],
   "source": [
    "from main import Trainer, show_misclassification, show_loss_curves\n",
    "from models import resnet #, cus_resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3820dd7f-210e-4605-acbc-645ee708ecc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading Data\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "            Conv2d-3           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-4           [-1, 64, 32, 32]             128\n",
      "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
      "        BasicBlock-7           [-1, 64, 32, 32]               0\n",
      "            Conv2d-8           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
      "           Conv2d-10           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-11           [-1, 64, 32, 32]             128\n",
      "       BasicBlock-12           [-1, 64, 32, 32]               0\n",
      "           Conv2d-13          [-1, 128, 16, 16]          73,728\n",
      "      BatchNorm2d-14          [-1, 128, 16, 16]             256\n",
      "           Conv2d-15          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-16          [-1, 128, 16, 16]             256\n",
      "           Conv2d-17          [-1, 128, 16, 16]           8,192\n",
      "      BatchNorm2d-18          [-1, 128, 16, 16]             256\n",
      "       BasicBlock-19          [-1, 128, 16, 16]               0\n",
      "           Conv2d-20          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-21          [-1, 128, 16, 16]             256\n",
      "           Conv2d-22          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 16, 16]             256\n",
      "       BasicBlock-24          [-1, 128, 16, 16]               0\n",
      "           Conv2d-25            [-1, 256, 8, 8]         294,912\n",
      "      BatchNorm2d-26            [-1, 256, 8, 8]             512\n",
      "           Conv2d-27            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-28            [-1, 256, 8, 8]             512\n",
      "           Conv2d-29            [-1, 256, 8, 8]          32,768\n",
      "      BatchNorm2d-30            [-1, 256, 8, 8]             512\n",
      "       BasicBlock-31            [-1, 256, 8, 8]               0\n",
      "           Conv2d-32            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-33            [-1, 256, 8, 8]             512\n",
      "           Conv2d-34            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-35            [-1, 256, 8, 8]             512\n",
      "       BasicBlock-36            [-1, 256, 8, 8]               0\n",
      "           Conv2d-37            [-1, 512, 4, 4]       1,179,648\n",
      "      BatchNorm2d-38            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-39            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-40            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-41            [-1, 512, 4, 4]         131,072\n",
      "      BatchNorm2d-42            [-1, 512, 4, 4]           1,024\n",
      "       BasicBlock-43            [-1, 512, 4, 4]               0\n",
      "           Conv2d-44            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-45            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-46            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-47            [-1, 512, 4, 4]           1,024\n",
      "       BasicBlock-48            [-1, 512, 4, 4]               0\n",
      "           Linear-49                  [-1, 200]         102,600\n",
      "================================================================\n",
      "Total params: 11,271,432\n",
      "Trainable params: 11,271,432\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 11.25\n",
      "Params size (MB): 43.00\n",
      "Estimated Total Size (MB): 54.26\n",
      "----------------------------------------------------------------\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.01\n",
      "    weight_decay: 0\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "Running LR finder ... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f781e83f56548f586d9d146691f7beb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate search finished. See the graph with {finder_name}.plot()\n",
      "LR suggestion: steepest gradient\n",
      "Suggested LR: 3.20E-02\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "few steps before and after best_loss\n",
      "(relative step, lr, loss)\n",
      "(-5, 0.4132, 5.23705)\n",
      "(-4, 0.43288, 5.23752)\n",
      "(-3, 0.45349, 5.23399)\n",
      "(-2, 0.47508, 5.23197)\n",
      "(-1, 0.4977, 5.23227)\n",
      "(0, 0.5214, 5.23114)\n",
      "(1, 0.54623, 5.23135)\n",
      "(2, 0.57224, 5.23136)\n",
      "(3, 0.59948, 5.24161)\n",
      "(4, 0.62803, 5.24746)\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# trainer = Trainer(\n",
    "#       resnet.ResNet18(num_classes=200), lr=0.01, batch_size=512, scheduler='RegularOCLR', optimizer='Adam', eval_model_on_load=False,\n",
    "#     label_smoothing=0.05, run_find_lr=True, epochs=50\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f358ceae-f074-4f92-81d4-6c0f3a94a75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading Data\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "            Conv2d-3           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-4           [-1, 64, 32, 32]             128\n",
      "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
      "        BasicBlock-7           [-1, 64, 32, 32]               0\n",
      "            Conv2d-8           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
      "           Conv2d-10           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-11           [-1, 64, 32, 32]             128\n",
      "       BasicBlock-12           [-1, 64, 32, 32]               0\n",
      "           Conv2d-13          [-1, 128, 16, 16]          73,728\n",
      "      BatchNorm2d-14          [-1, 128, 16, 16]             256\n",
      "           Conv2d-15          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-16          [-1, 128, 16, 16]             256\n",
      "           Conv2d-17          [-1, 128, 16, 16]           8,192\n",
      "      BatchNorm2d-18          [-1, 128, 16, 16]             256\n",
      "       BasicBlock-19          [-1, 128, 16, 16]               0\n",
      "           Conv2d-20          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-21          [-1, 128, 16, 16]             256\n",
      "           Conv2d-22          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 16, 16]             256\n",
      "       BasicBlock-24          [-1, 128, 16, 16]               0\n",
      "           Conv2d-25            [-1, 256, 8, 8]         294,912\n",
      "      BatchNorm2d-26            [-1, 256, 8, 8]             512\n",
      "           Conv2d-27            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-28            [-1, 256, 8, 8]             512\n",
      "           Conv2d-29            [-1, 256, 8, 8]          32,768\n",
      "      BatchNorm2d-30            [-1, 256, 8, 8]             512\n",
      "       BasicBlock-31            [-1, 256, 8, 8]               0\n",
      "           Conv2d-32            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-33            [-1, 256, 8, 8]             512\n",
      "           Conv2d-34            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-35            [-1, 256, 8, 8]             512\n",
      "       BasicBlock-36            [-1, 256, 8, 8]               0\n",
      "           Conv2d-37            [-1, 512, 4, 4]       1,179,648\n",
      "      BatchNorm2d-38            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-39            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-40            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-41            [-1, 512, 4, 4]         131,072\n",
      "      BatchNorm2d-42            [-1, 512, 4, 4]           1,024\n",
      "       BasicBlock-43            [-1, 512, 4, 4]               0\n",
      "           Conv2d-44            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-45            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-46            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-47            [-1, 512, 4, 4]           1,024\n",
      "       BasicBlock-48            [-1, 512, 4, 4]               0\n",
      "           Linear-49                  [-1, 200]         102,600\n",
      "================================================================\n",
      "Total params: 11,271,432\n",
      "Trainable params: 11,271,432\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 11.25\n",
      "Params size (MB): 43.00\n",
      "Estimated Total Size (MB): 54.26\n",
      "----------------------------------------------------------------\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.03\n",
      "    weight_decay: 0\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "      resnet.ResNet18(num_classes=200), lr=0.03, batch_size=512, scheduler='RegularOCLR', optimizer='Adam', eval_model_on_load=False,\n",
    "    label_smoothing=0.05, run_find_lr=False, epochs=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91de389-916e-4006-855f-3d31dc94a714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Begin training for 40 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:0 Loss:4.9952 Batch:150 Acc:2.74: 100%|██████████| 151/151 [05:16<00:00,  2.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:4.8815         Acc:4.78         [1576 / 33000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:1 Loss:4.4532 Batch:150 Acc:6.55: 100%|██████████| 151/151 [04:55<00:00,  1.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:4.4146         Acc:8.90         [2936 / 33000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:2 Loss:3.6964 Batch:150 Acc:11.72: 100%|██████████| 151/151 [05:23<00:00,  2.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:4.0434         Acc:14.81         [4886 / 33000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:3 Loss:3.8201 Batch:150 Acc:17.03: 100%|██████████| 151/151 [05:14<00:00,  2.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:3.7531         Acc:20.52         [6772 / 33000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:4 Loss:3.611 Batch:150 Acc:22.48: 100%|██████████| 151/151 [05:10<00:00,  2.06s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:3.5475         Acc:24.45         [8070 / 33000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:5 Loss:3.2511 Batch:150 Acc:27.14: 100%|██████████| 151/151 [05:29<00:00,  2.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:3.4673         Acc:26.07         [8604 / 33000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:6 Loss:3.2491 Batch:150 Acc:32.08: 100%|██████████| 151/151 [04:58<00:00,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:3.2962         Acc:30.44         [10046 / 33000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:7 Loss:2.7027 Batch:150 Acc:36.20: 100%|██████████| 151/151 [05:25<00:00,  2.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:3.3030         Acc:30.40         [10032 / 33000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:8 Loss:2.643 Batch:150 Acc:40.32: 100%|██████████| 151/151 [05:18<00:00,  2.11s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:3.2156         Acc:33.50         [11054 / 33000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:9 Loss:2.5807 Batch:150 Acc:44.01: 100%|██████████| 151/151 [05:04<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:2.9368         Acc:38.44         [12685 / 33000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:10 Loss:2.5135 Batch:150 Acc:47.41: 100%|██████████| 151/151 [05:27<00:00,  2.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:2.8717         Acc:40.43         [13341 / 33000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:11 Loss:2.4404 Batch:150 Acc:50.93: 100%|██████████| 151/151 [05:01<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:2.7180         Acc:44.15         [14571 / 33000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:12 Loss:2.1137 Batch:150 Acc:53.87: 100%|██████████| 151/151 [05:21<00:00,  2.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:2.9123         Acc:40.81         [13467 / 33000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:13 Loss:2.2871 Batch:150 Acc:56.67: 100%|██████████| 151/151 [05:22<00:00,  2.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:2.8027         Acc:43.30         [14289 / 33000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:14 Loss:1.9516 Batch:150 Acc:59.64: 100%|██████████| 151/151 [04:59<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:2.7266         Acc:44.69         [14747 / 33000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:15 Loss:2.009 Batch:150 Acc:62.46: 100%|██████████| 151/151 [05:26<00:00,  2.16s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:2.6933         Acc:46.62         [15383 / 33000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:16 Loss:1.8804 Batch:150 Acc:65.34: 100%|██████████| 151/151 [05:06<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:2.7272         Acc:46.02         [15187 / 33000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:17 Loss:1.7632 Batch:150 Acc:68.08: 100%|██████████| 151/151 [05:17<00:00,  2.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:2.7781         Acc:46.14         [15227 / 33000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:18 Loss:1.6659 Batch:150 Acc:70.90: 100%|██████████| 151/151 [05:24<00:00,  2.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:2.6958         Acc:48.24         [15918 / 33000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:19 Loss:1.4148 Batch:150 Acc:73.80: 100%|██████████| 151/151 [04:56<00:00,  1.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:2.8164         Acc:46.88         [15471 / 33000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:20 Loss:1.4251 Batch:150 Acc:76.42: 100%|██████████| 151/151 [05:27<00:00,  2.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:2.7530         Acc:47.65         [15724 / 33000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:21 Loss:1.4945 Batch:150 Acc:79.16: 100%|██████████| 151/151 [05:10<00:00,  2.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:2.8030         Acc:47.33         [15618 / 33000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:22 Loss:1.2799 Batch:150 Acc:81.60: 100%|██████████| 151/151 [05:10<00:00,  2.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:2.7790         Acc:48.43         [15982 / 33000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:23 Loss:1.3351 Batch:150 Acc:83.99: 100%|██████████| 151/151 [05:24<00:00,  2.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:2.7362         Acc:49.42         [16309 / 33000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:24 Loss:1.2798 Batch:150 Acc:86.11: 100%|██████████| 151/151 [04:58<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:2.7845         Acc:49.44         [16315 / 33000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:25 Loss:1.0848 Batch:150 Acc:87.99: 100%|██████████| 151/151 [05:25<00:00,  2.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:2.7818         Acc:50.31         [16602 / 33000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:26 Loss:1.0384 Batch:150 Acc:89.71: 100%|██████████| 151/151 [05:17<00:00,  2.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:2.7323         Acc:50.62         [16705 / 33000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:27 Loss:0.9941 Batch:150 Acc:91.05: 100%|██████████| 151/151 [05:06<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:2.7031         Acc:50.47         [16655 / 33000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:28 Loss:1.0151 Batch:150 Acc:92.39: 100%|██████████| 151/151 [05:25<00:00,  2.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:2.7201         Acc:50.54         [16678 / 33000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:29 Loss:0.9009 Batch:150 Acc:93.51: 100%|██████████| 151/151 [05:01<00:00,  2.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:2.6668         Acc:51.12         [16871 / 33000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:30 Loss:0.8384 Batch:150 Acc:94.24: 100%|██████████| 151/151 [05:22<00:00,  2.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:2.6623         Acc:51.14         [16876 / 33000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:31 Loss:0.8512 Batch:150 Acc:95.09: 100%|██████████| 151/151 [05:21<00:00,  2.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:2.6349         Acc:51.64         [17040 / 33000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:32 Loss:0.8769 Batch:150 Acc:95.63: 100%|██████████| 151/151 [05:01<00:00,  2.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:2.6126         Acc:52.02         [17168 / 33000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:33 Loss:0.773 Batch:70 Acc:96.37:  47%|████▋     | 71/151 [02:35<02:53,  2.17s/it] "
     ]
    }
   ],
   "source": [
    "trainer.train_model(epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0c089f-12fa-4ef8-b145-08085da81a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'epoch': 40,\n",
    "            'model_state_dict': trainer.net.state_dict(),\n",
    "            'optimizer_state_dict': trainer.optimizer.state_dict(),\n",
    "            'logs': trainer.logs,\n",
    "            'lr_logs': trainer.lr_logs\n",
    "            }, 's10_resnet18_epochs40.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f17d1fe-1ec3-4902-8503-747997b7fab2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
